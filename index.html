<!DOCTYPE html>
<html lang="en">
    <head>
	<!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-VR953VMVXR"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-VR953VMVXR');
    </script>
        <title>Harvey Yiyun Fu</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta property="og:url" content="http://harvey-fin.github.io" />
	    <meta property="og:title" content="Harvey Yiyun Fu" />
	    <meta property="og:image" content="http://harvey-fin.github.io/img/harvey-fu-2023.png" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="author" content="Harvey Yiyun Fu">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <!-- <link rel="shortcut icon" type="image/png" href="favicon.ico"/> -->

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="css/style.css">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" crossorigin="anonymous">
        <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
    </head>
    <body>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col-lg-3 col-md-4">
                    <img class="img-fluid rounded" src="img/harvey-fu-2023.png" alt="Harvey Fu">
                    <p>
                        <i class="fa fa-envelope pt-3"></i> harveyfu [at] uchicago.edu
                    </p>
                </div>
                <div class="col-lg-9 col-md-8">
                    <h1>(Harvey) Yiyun Fu</h1>
                    <p>
                        Welcome! I am a first year Ph.D. student in Computer Science at
                        the Univeristy of Chicago, advised by <a href="https://ariholtzman.com/" style="color:#800000"
                        target="_blank">Prof. Ari Holtzman</a> and within <a href="https://ci.cs.uchicago.edu/" style="color:#800000"
                        target="_blank">UChicago C&I</a>. Prior to UChicago, I received B.S. in Economics and Mathematics from the 
                        University of Southern California.
                    </p>
                    <p>
                        I have a broad interest in natural language processing and machine learning. 
                        My current research focus lies in understanding language model capabilities, as well as building 
                        generalizable and robust NLP systems. Recently, I am interested in LLM mathematical reasoning hallucinations.
                    </p>
                    <p>
                        I am extremely grateful to all of my mentors and collaborators who warmly guided me into the field of NLP Research. 
                    </p>
                    <p>
                        [<a href="files/harvey_fu_cv.pdf" style="color:#800000" target="_blank">CV</a>] [<a href="https://twitter.com/harveyiyun" style="color:#800000" target="_blank">Twitter</a>]
                         [<a href="https://scholar.google.com/citations?user=0ZBEwDUAAAAJ&hl=en&oi=ao" style="color:#800000" target="_blank">Google Scholar</a>]
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h2>Recent News</h2>
                    <ul>
                        <li>
                            [Jun 2025] We release a new [<a href="https://arxiv.org/abs/2506.11440" style="color:#800000" target="_blank">benchmark</a> that tests language models' capacity to detect missing information over long-context inputs.
                        </li>
                        <li>
                            [Oct 2023] Two papers [<a href="https://arxiv.org/abs/2305.14802" style="color:#800000" target="_blank">1</a>, <a href="https://arxiv.org/abs/2305.14947" style="color:#800000" target="_blank">2</a>] are accepted to EMNLP 2023 Findings.
                        </li>
                        <li>
                            [May 2023] Check out our new preprints [<a href="https://arxiv.org/abs/2305.14802" style="color:#800000" target="_blank">1</a>, 
                            <a href="https://arxiv.org/abs/2305.14947" style="color:#800000" target="_blank">2</a>] on understanding large language model capabilities.
                        </li>
                        <li>
                            [May 2023] I received the USC Provost's Research Fellowship.
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row" id="publications">
                <div class="col">
                    <h2>Publications</h2>
                    <ul class="pl">
                        <li>
                            <a href="https://arxiv.org/abs/2506.11440" style="color:#800000" target="_blank">
                                <b>AbsenceBench: Language Models Can't Tell What's Missing</b>
                            </a>
                            <br/>
                            <b>Harvey Yiyun Fu</b>,
                            <a href="https://www.linkedin.com/in/aryan-shrivastava123" style="color:#800000" target="_blank">Aryan Shrivastava</a>,
                            <a href="https://jaredmoore.org/" style="color:#800000" target="_blank">Jared Moore</a>,
                            <a href="https://peterwestai.notion.site/" style="color:#800000" target="_blank">Peter West</a>,
                            <a href="https://chenhaot.com/" style="color:#800000" target="_blank">Chenhao Tan</a>,
                            and <a href="https://ariholtzman.com/" style="color:#800000" target="_blank">Ari Holtzman</a>.
                            <br/>
                            arxiv preprint
                            <br/>
                            <!-- [<a href="papers/dasigi+liu+marasovic+smith+gardner.emnlp2019.bib" target="_blank">bib</a>] -->
                            [<a href="#" style="color:#800000" onclick="$('#harvey_absence_abstract').toggle();return false;">abstract</a>]
			                [<a href="https://github.com/harvey-fin/absence-bench" style="color:#800000" target="_blank">code</a>]
                            <div id="harvey_absence_abstract" class="abstract" style="display:none;">
                                <p>
                                    Large language models (LLMs) are increasingly capable of processing 
                                    long inputs and locating specific information within them, as evidenced 
                                    by their performance on the Needle in a Haystack (NIAH) test. However, 
                                    while models excel at recalling surprising information, they still 
                                    struggle to identify clearly omitted information. We introduce 
                                    AbsenceBench to assesses LLMs' capacity to detect missing information 
                                    across three domains: numerical sequences, poetry, and GitHub pull 
                                    requests. AbsenceBench asks models to identify which pieces of a 
                                    document were deliberately removed, given access to both the original 
                                    and edited contexts. Despite the apparent straightforwardness of 
                                    these tasks, our experiments reveal that even state-of-the-art models 
                                    like Claude-3.7-Sonnet achieve only 69.6% F1-score with a modest 
                                    average context length of 5K tokens. Our analysis suggests this poor 
                                    performance stems from a fundamental limitation: Transformer attention 
                                    mechanisms cannot easily attend to "gaps" in documents since these 
                                    absences don't correspond to any specific keys that can be attended to. 
                                    Overall, our results and analysis provide a case study of the close 
                                    proximity of tasks where models are already superhuman (NIAH) and 
                                    tasks where models breakdown unexpectedly (AbsenceBench).
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="https://arxiv.org/abs/2305.14802" style="color:#800000" target="_blank">
                                <b>Estimating Large Language Model Capabilities without Labeled Test Data</b>
                            </a>
                            <br/>
                            <b>Harvey Yiyun Fu</b>,
                            <a href="http://yeqy.xyz/" style="color:#800000" target="_blank">Qinyuan Ye</a>,
                            <a href="https://albertxu.xyz/" style="color:#800000" target="_blank">Albert Xu</a>,
                            <a href="https://shanzhenren.github.io/" style="color:#800000" target="_blank">Xiang Ren</a>,
                            and <a href="https://robinjia.github.io/" style="color:#800000" target="_blank">Robin Jia</a>.
                            <br/>
                            Findings of EMNLP, 2023.
                            <br/>
                            <!-- [<a href="papers/dasigi+liu+marasovic+smith+gardner.emnlp2019.bib" target="_blank">bib</a>] -->
                            [<a href="#" style="color:#800000" onclick="$('#harvey_estimating_abstract').toggle();return false;">abstract</a>]
			                [<a href="https://github.com/harvey-fin/icl-estimate" style="color:#800000" target="_blank">code</a>]
                            <div id="harvey_estimating_abstract" class="abstract" style="display:none;">
                                <p>
                                    Large Language Models (LLMs) have the impressive ability to perform 
                                    in-context learning (ICL) from only a few examples, but the success of 
                                    ICL varies widely from task to task. Thus, it is important to quickly 
                                    determine whether ICL is applicable to a new task, but directly evaluating 
                                    ICL accuracy can be expensive in situations where test data is expensive 
                                    to annotate---the exact situations where ICL is most appealing. In this 
                                    paper, we propose the task of ICL accuracy estimation, in which we predict 
                                    the accuracy of an LLM when doing in-context learning on a new task 
                                    given only unlabeled test data for that task. To perform ICL accuracy 
                                    estimation, we propose a method that trains a meta-model using LLM 
                                    confidence scores as features. We compare our method to several 
                                    strong accuracy estimation baselines on a new benchmark that covers 
                                    4 LLMs and 3 task collections. The meta-model improves over all 
                                    baselines across 8 out of 12 settings and achieves the same estimation 
                                    performance as directly evaluating on 40 collected labeled test examples 
                                    per task.  At the same time, no existing approach provides an accurate 
                                    and reliable ICL accuracy estimation in every setting, highlighting the 
                                    need for better ways to measure the uncertainty of LLM predictions.
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="https://arxiv.org/abs/2305.14947" style="color:#800000" target="_blank">
                                <b>How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench</b>
                            </a>
                            <br/>
                            <a href="http://yeqy.xyz/" style="color:#800000" target="_blank">Qinyuan Ye</a>,
                            <b>Harvey Yiyun Fu</b>,
                            <a href="https://shanzhenren.github.io/" style="color:#800000" target="_blank">Xiang Ren</a>,
                            and <a href="https://robinjia.github.io/" style="color:#800000" target="_blank">Robin Jia</a>.
                            <br/>
                            Findings of EMNLP, 2023.
                            <br/>
                            [<a href="#" style="color:#800000" onclick="$('#qinyuan_how_predictable_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://github.com/INK-USC/predicting-big-bench" style="color:#800000" target="_blank">code</a>]
                            <div id="qinyuan_how_predictable_abstract" class="abstract" style="display:none;">
                                <p>
                                    We investigate the predictability of large 
                                    language model (LLM) capabilities: given records 
                                    of past experiments using different model families, 
                                    numbers of parameters, tasks, and numbers of in-context 
                                    examples, can we accurately predict LLM performance 
                                    on new experiment configurations? Answering this question 
                                    has practical implications for LLM users (e.g., 
                                    deciding which models to try), developers (e.g., 
                                    prioritizing evaluation on representative tasks), and 
                                    the research community (e.g., identifying 
                                    hard-to-predict capabilities that warrant further investigation). 
                                    We study the performance prediction problem on experiment 
                                    records from BIG-bench. On a random train-test split, 
                                    an MLP-based predictor achieves an R^2 score greater 
                                    than 95%, indicating the presence of learnable patterns 
                                    within the experiment records. We then formulate the problem 
                                    of searching for "small-bench," an informative subset 
                                    of BIG-bench tasks from which the performance on the full 
                                    set can be maximally recovered. We find a subset as 
                                    informative as BIG-bench Hard for evaluating new model 
                                    families, while being 3 times smaller. We also find 
                                    competitive subsets by clustering task representations 
                                    learned by the MLP-based predictor, highlighting the 
                                    importance of task diversity in constructing "small-bench."
                                </p>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Teaching</h2>
                    <ul>
                        <li>
                            ITP115: Programming in Python: Fall 2022, Spring 2023, Fall 2023
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Miscellany</h2>
                    <ul>
                        <li>
                            I play basketball in my free time. I am also a semi-fluent bamboo flute player.
                        </li>
                        <li>
                            I enjoy reading science-fiction as a way to think outside the box, especially for 
                            those with Artificial Intelligence elements. Often times I take that as a research motivation. 
                        </li>
                        <li>
                            This website is adapted from <a href="https://nelsonliu.me/"
                            style="color:#800000" target="_blank">Nelson's</a>.
                        </li>
                    </ul>
                </div>
            </div>
            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                        <p class="h5 text-muted">
                            Last update: Jun 16, 2025
                        </p>
                    </div>
                    <div class="col-6 col-md text-right">
                        <a href="https://www.usc.edu/" class="image-link">
                            <img class="mr-4" src="img/usc_img.png" alt="USC Homepage." height="100">
                            <img class="mr-4" src="img/uchicago_img.png" alt="UChicago Homepage." height="100">
                        </a>
                    </div>
                </div>
            </footer>
        </div>
    </body>
</html>
